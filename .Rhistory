(Pai <- A*(2*(Pa*Pi))/((Pa^2)+(2*(Pa*Pi))))
(Pbb <- B*(Pb^2/((Pb^2)+(2*(Pb*Pi)))))
(Pbi <- B*(2*(Pb*Pi))/((Pb^2)+(2*(Pb*Pi))))
(N <- AB + A + B + O)
EM <- function(Pi, Pa, Pb){
while((round(Pi0,12) == round(Pi,12))==FALSE &&
(round(Pb0,12) == round(Pb,12))==FALSE){
AB <- 131
A <- 862
B <- 365
O <- 702
(N <- AB + A + B + O)
AB <- 12
A <- 96
B <- 50
O <- 123
(Pi <- sqrt(O/N))
(Pa <- sqrt((A+O)/N)-Pi)
(Pb <- sqrt((B+O)/N)-Pi)
Pa + Pb + Pi
(Pi <- sqrt(O/N))
(Pa <- sqrt((A+O)/N)-Pi)
(Pb <- sqrt((B+O)/N)-Pi)
Pa + Pb + Pi
signif(Pa + Pb + Pi, 2)
AB <- 12
A <- 96
B <- 50
O <- 123
(N <- AB + A + B + O)
(Pi <- sqrt(O/N))
(Pa <- sqrt((A+O)/N)-Pi)
(Pb <- sqrt((B+O)/N)-Pi)
Pa + Pb + Pi
signif(Pa + Pb + Pi, 2)
EM <- function(Pi, Pa, Pb){
while((round(Pi0,12) == round(Pi,12))==FALSE && (round(Pa0,12) == round(Pa,12))==FALSE && (round(Pb0,12) == round(Pb,12))==FALSE)
{
Pi0 <- Pi
Pa0 <- Pa
Pb0 <- Pb
Paa <- A*(Pa0^2/((Pa0^2)+(2*(Pa0*Pi0))))
Pai <- A*(2*(Pa0*Pi0))/((Pa0^2)+(2*(Pa0*Pi0)))
Pbb <- B*(Pb0^2/((Pb0^2)+(2*(Pb0*Pi0))))
Pbi <- B*(2*(Pb0*Pi0))/((Pb0^2)+(2*(Pb0*Pi0)))
Pii <- O
Pab <- AB
(Pa <- ((2*Paa)+Pai+Pab)/(2*N))
(Pb <- ((2*Pbb)+Pbi+Pab)/(2*N))
(Pi <- ((2*Pii)+Pai+Pbi)/(2*N))
counter<-counter+1
}
return(c(paste("Pi =",Pi, ", Pa =", Pa, ", Pb =", Pb, ", Number of loops =", counter)))
}
counter <- 0
EM(Pi,Pa,Pb)
Pi0 <- NULL
Pa0 <- NULL
Pb0 <- NULL
counter <- 0
EM <- function(Pi, Pa, Pb){
while((round(Pi0,12) == round(Pi,12))==FALSE && (round(Pa0,12) == round(Pa,12))==FALSE && (round(Pb0,12) == round(Pb,12))==FALSE)
{
Pi0 <- Pi
Pa0 <- Pa
Pb0 <- Pb
Paa <- A*(Pa0^2/((Pa0^2)+(2*(Pa0*Pi0))))
Pai <- A*(2*(Pa0*Pi0))/((Pa0^2)+(2*(Pa0*Pi0)))
Pbb <- B*(Pb0^2/((Pb0^2)+(2*(Pb0*Pi0))))
Pbi <- B*(2*(Pb0*Pi0))/((Pb0^2)+(2*(Pb0*Pi0)))
Pii <- O
Pab <- AB
(Pa <- ((2*Paa)+Pai+Pab)/(2*N))
(Pb <- ((2*Pbb)+Pbi+Pab)/(2*N))
(Pi <- ((2*Pii)+Pai+Pbi)/(2*N))
counter<-counter+1
}
return(c(paste("Pi =",Pi, ", Pa =", Pa, ", Pb =", Pb, ", Number of loops =", counter)))
}
EM(Pi,Pa,Pb)
Pi0
Pi0 <- NULL
Pa0 <- NULL
Pb0 <- NULL
Pi0
Pa0
Pb0
Pi
round(Pi0,12)
class(Pi0)
round(0,12)
Pi0 <- 0
Pa0 <- 0
Pb0 <- 0
counter <- 0
EM <- function(Pi, Pa, Pb){
while((round(Pi0,12) == round(Pi,12))==FALSE && (round(Pa0,12) == round(Pa,12))==FALSE && (round(Pb0,12) == round(Pb,12))==FALSE)
{
Pi0 <- Pi
Pa0 <- Pa
Pb0 <- Pb
Paa <- A*(Pa0^2/((Pa0^2)+(2*(Pa0*Pi0))))
Pai <- A*(2*(Pa0*Pi0))/((Pa0^2)+(2*(Pa0*Pi0)))
Pbb <- B*(Pb0^2/((Pb0^2)+(2*(Pb0*Pi0))))
Pbi <- B*(2*(Pb0*Pi0))/((Pb0^2)+(2*(Pb0*Pi0)))
Pii <- O
Pab <- AB
(Pa <- ((2*Paa)+Pai+Pab)/(2*N))
(Pb <- ((2*Pbb)+Pbi+Pab)/(2*N))
(Pi <- ((2*Pii)+Pai+Pbi)/(2*N))
counter<-counter+1
}
return(c(paste("Pi =",Pi, ", Pa =", Pa, ", Pb =", Pb, ", Number of loops =", counter)))
}
EM(Pi,Pa,Pb)
EM(Pi,Pa,Pb)
EM(Pi,Pa,Pb)
AB <- 131
A <- 862
B <- 365
O <- 702
(N <- AB + A + B + O)
Pi0 <- 0
Pa0 <- 0
Pb0 <- 0
counter <- 0
EM(Pi,Pa,Pb)
EM <- function(Pi, Pa, Pb){
while((round(Pi0,12) == round(Pi,12))==FALSE && (round(Pa0,12) == round(Pa,12))==FALSE && (round(Pb0,12) == round(Pb,12))==FALSE)
{
Pi0 <- Pi
Pa0 <- Pa
Pb0 <- Pb
Paa <- A*(Pa0^2/((Pa0^2)+(2*(Pa0*Pi0))))
Pai <- A*(2*(Pa0*Pi0))/((Pa0^2)+(2*(Pa0*Pi0)))
Pbb <- B*(Pb0^2/((Pb0^2)+(2*(Pb0*Pi0))))
Pbi <- B*(2*(Pb0*Pi0))/((Pb0^2)+(2*(Pb0*Pi0)))
Pii <- O
Pab <- AB
(Pa <- ((2*Paa)+Pai+Pab)/(2*N))
(Pb <- ((2*Pbb)+Pbi+Pab)/(2*N))
(Pi <- ((2*Pii)+Pai+Pbi)/(2*N))
counter<-counter+1
}
return(c(paste("Pi =",Pi, ", Pa =", Pa, ", Pb =", Pb, ", Number of loops =", counter)))
}
getwd()
setwd("/Users/akijarl/Desktop/PostDoc/NovelOceanClim/OceanClimateNovelty/data/real_data/")
list.files()
??fread
library(data.table)
HOT<-fread("HOT_bottle_data.txt")
head(HOT)
install.packages("bit64")
HOT<-fread("HOT_bottle_data.txt")
BATS<-fread("BATS_bottle_data.txt")
head(BATS)
rm(BATS)
?fread
BATS<-fread("BATS_bottle_data.txt", sep=",")
BATS<-fread("BATS_bottle_data_mod.txt", sep=",")
head(BATS)
BATS<-fread("BATS_bottle_data_mod.txt")
head(BATS)
BATS2<-fread("BATS_bottle_data_mod2.txt")
head(BATS2)
rm(BATS2)
BATS<-fread("BATS_bottle_data_mod.txt")
str(HOT)
head(HOT)
summary(HOT$V16)
HOT<-fread("HOT_bottle_data_mod.txt")
head(HOT)
head(BATS)
head(HOT)
head(HOT[which(HOT$temp(ITS-90)==-9),])
head(HOT[which(HOT$"temp(ITS-90)"==-9),])
head(HOT[which(HOT$"temp(ITS-90)"!=-9),])
head(HOT[which(HOT$`csal(PSS-78)`==-9),])
dim(HOT[which(HOT$`csal(PSS-78)`!=-9),])
dim(HOT[which(HOT$`bsal(PSS-78)`!=-9),])
dim(HOT[which(HOT$temp(ITS-90)!=-9) && which(HOT$`csal(PSS-78)`1=-9) ,])
dim(HOT[which(HOT$temp(ITS-90)!=-9) | which(HOT$`csal(PSS-78)`1=-9) ,])
dim(HOT[which(HOT$temp(ITS-90)!=-9) && which(HOT$`csal(PSS-78)'!=-9) ,])
dim(HOT[which(HOT$temp(ITS-90)!=-9) && which(HOT$`csal(PSS-78)'!=-9) ,]))
dim(HOT[which(HOT$"temp(ITS-90)"!=-9) && which(HOT$"csal(PSS-78)"!=-9) ,]))
dim(HOT[which(HOT$"temp(ITS-90)"!=-9) && which(HOT$"csal(PSS-78)"!=-9) ,])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9) | which(HOT$"csal(PSS-78)"!=-9) ,])
head(HOT[which(HOT$temp(ITS-90)!=-9 | HOT$csal(PSS-78)!=-9) ,] )
head(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9) ,])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9) ,])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9) | HOT$"dic(umol/kg)"!= -9 | HOT$`alk(ueq/kg)` != -9 ,])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9) | HOT$"dic(umol/kg)"!= -9 | HOT$"alk(ueq/kg)" != -9 ,])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9) | HOT$"dic(umol/kg)"!= -9 | HOT$"alk(ueq/kg)"!= -9 ,])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9) | HOT$"dic(umol/kg)"!= -9,])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9),])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9 | HOT$"dic(umol/kg)"!= -9 | HOT$"alk(ueq/kg)"!= -9),])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9 | HOT$"dic(umol/kg)"!= -9 | HOT$"alk(ueq/kg)"!= -9 | HOT$ph!= -9),])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9 | HOT$"dic(umol/kg)"!= -9 | HOT$"alk(ueq/kg)"!= -9),])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9 | HOT$"dic(umol/kg)"!= -9),])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 | HOT$"csal(PSS-78)"!=-9),])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9),])
dim(HOT[which(HOT$"csal(PSS-78)"!=-9),])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 & HOT$"csal(PSS-78)"!=-9 & HOT$"dic(umol/kg)"!= -9 & HOT$"alk(ueq/kg)"!= -9 & HOT$ph!= -9),])
dim(HOT[which(HOT$"temp(ITS-90)"!=-9 & HOT$"csal(PSS-78)"!=-9 & HOT$"dic(umol/kg)"!= -9 & HOT$"alk(ueq/kg)"!= -9),])
HOT_filt<-HOT[which(HOT$"temp(ITS-90)"!=-9 & HOT$"csal(PSS-78)"!=-9 & HOT$"dic(umol/kg)"!= -9 & HOT$"alk(ueq/kg)"!= -9),]
head(HOT)
HOT_filt<-HOT[which(HOT$"temp(ITS-90)"!=-9 && HOT$"csal(PSS-78)"!=-9 && HOT$"dic(umol/kg)"!= -9 && HOT$"alk(ueq/kg)"!= -9),]
head(HOT)
HOT_filt<-HOT[which(HOT$"temp(ITS-90)"!=-9 & HOT$"csal(PSS-78)"!=-9 & HOT$"dic(umol/kg)"!= -9 & HOT$"alk(ueq/kg)"!= -9),]
head(HOT_filt)
tail(HOT_filt)
head(BATS)
dim(BATS[BATS$CTD_S!=-9,])
dim(BATS[BATS$CTD_S!=-999,])
dim(BATS[BATS$Sal1!=-999,])
BATS_filt<-BATS[which(BATS$Temp!=-999 & BATS$CTD_S!=-999 & BATS$CO2!= -999 & BATS$Alk!= -999),]
head(BATS_filt)
getwd()
write.table(HOT_filt, "HOT_filt.txt", quote=F, sep=",", row.names = F)
write.table(BATS_filt, "BATS_filt.txt", quote=F, sep=",", row.names = F)
## Specify location of data
#setwd("/Users/katie/Desktop/OceanClimateNovelty/")
setwd("~/Desktop/PostDoc/NovelOceanClim/OceanClimateNovelty/")
source("src/Novelty_Oceans_Functions.R")
list.files
list.files()
list.files("./datat")
list.files("./data")
#write.csv(NN.sigma,"NN.sigma.RCP45.GlobalMean.2085.csv", row.names=FALSE)
#write.csv(B2,"Sigma.RCP85.today_1800.csv", row.names=FALSE)
B2<-fread("./data/Sigma.RCP85.today_1800.csv")
head(B2)
##Interpolation for visualization
B2a<-B2[!is.na(B2$NN.sigma),]
B2a<-B2a[,c(4,3,2)]
for(i in 1:nrow(B2a)){
if(B2a$long[i]>360){
B2a$long[i]<-B2a$long[i]-360
}
}
EB2 <- SpatialPoints(B2a) # this is your spatial points df
# Project sp object to WGS 84
proj4string(EB2) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")
# Create an empty grid; n = number of cells
# Increase n to increase resolution
gr <- as.data.frame(spsample(EB2, 'regular', n  = 50000))
names(gr) <- c('X', 'Y')
coordinates(gr) <- c('X', 'Y')
gridded(gr) <- TRUE
fullgrid(gr) <- TRUE  # Create SpatialGrid object
proj4string(gr) <- proj4string(EB2)
gr <- as.data.frame(spsample(EB2, 'regular', n  = 50000))
names(gr) <- c('X', 'Y')
coordinates(gr) <- c('X', 'Y')
gridded(gr) <- TRUE
fullgrid(gr) <- TRUE  # Create SpatialGrid object
proj4string(gr) <- proj4string(EB2)
gr <- as.data.frame(spsample(EB2, 'regular', n  = 50000))
names(gr) <- c('X', 'Y')
coordinates(gr) <- c('X', 'Y')
gridded(gr) <- TRUE
fullgrid(gr) <- TRUE  # Create SpatialGrid object
proj4string(gr) <- proj4string(EB2)
# Interpolate the grid cells using inverse distance weighing power = 8
# NN.sigma ~ 1 = simple kriging
EB2.idw <- idw(NN.sigma ~ 1, EB2, newdata = gr, idp = 8)
# Convert to raster
r <- raster(EB2.idw)
world<-map("world2", fill=T,plot=F)
y<-map2SpatialPolygons(world, IDs = sapply(strsplit(world$names, ":"), function(x) x[1]), proj4string=CRS("+proj=longlat +datum=WGS84"))
z<-st_as_sf(y)
wr <- raster(z, res = 0.01)
wrld_r <- fasterize(z, wr)
gplot_wrld_r <- gplot_data(wrld_r)
gplot_r <- gplot_data(r)
#Change scale_fill_gradient value to name of variable
ggplot() +
geom_tile(data = gplot_r,
aes(x = x, y = y, fill = value)) +
geom_tile(data = dplyr::filter(gplot_wrld_r, !is.na(value)),
aes(x = x, y = y), fill = "grey20") +
ylim(-78,90) +
xlab("Long") +
ylab("Lat") +
ggtitle("Sigma dissimilarity: Today from 1800") +
theme(plot.title = element_text(hjust = 0.5)) +
scale_fill_gradient2(expression(paste(sigma," dis.")),
low = 'blue', mid = "yellow", high = 'red',
midpoint = 4,
na.value = NA) +
coord_quickmap()
plot(r)
plot(gplot_r)
ggplot() +
geom_tile(data = gplot_r,
aes(x = x, y = y, fill = value)) +
geom_tile(data = dplyr::filter(gplot_wrld_r, !is.na(value)),
aes(x = x, y = y), fill = "grey20") +
ggtitle("Sigma dissimilarity: Today from 1800") +
theme(plot.title = element_text(hjust = 0.5)) +
scale_fill_gradient2(expression(paste(sigma," dis.")),
low = 'blue', mid = "yellow", high = 'red',
midpoint = 2,
na.value = NA) +
coord_quickmap()
ggplot() +
geom_tile(data = gplot_r,
aes(x = x, y = y, fill = value)) +
#geom_tile(data = dplyr::filter(gplot_wrld_r, !is.na(value)),
#          aes(x = x, y = y), fill = "grey20") +
ggtitle("Sigma dissimilarity: Today from 1800") +
theme(plot.title = element_text(hjust = 0.5)) +
scale_fill_gradient2(expression(paste(sigma," dis.")),
low = 'blue', mid = "yellow", high = 'red',
midpoint = 2,
na.value = NA) +
coord_quickmap()
ggplot() +
#geom_tile(data = gplot_r,
#          aes(x = x, y = y, fill = value)) +
geom_tile(data = dplyr::filter(gplot_wrld_r, !is.na(value)),
aes(x = x, y = y), fill = "grey20") +
ggtitle("Sigma dissimilarity: Today from 1800") +
theme(plot.title = element_text(hjust = 0.5)) +
#scale_fill_gradient2(expression(paste(sigma," dis.")),
#                    low = 'blue', mid = "yellow", high = 'red',
#                     midpoint = 2,
#                     na.value = NA) +
coord_quickmap()
head(gplot_wrld_r)
head(gplot_r)
# Visualize
world <- map_data("world2")
dim(stationInfo)
Plot_nonInt(B2$lat, B2$long,
B2$NN.sigma, world, "sigma dis.")
#dat <- fread("data/large_files/Data_OceNov.txt", sep = ",")
dat <- fread("data/large_files/ESM2M_2000_RCP8.5.txt", sep = ",")
#--------------------------------
### data frame to link station number to Lat Long ####
#--------------------------------
head(dat)
min(which(dat$No==2))
stations <- unique(dat$No)
stationInfo = data.frame(stations=stations, lat=NA, long=NA)
unik <- which(!duplicated(dat$No))
head(unik)
stationInfo$lat <- dat$Lat[unik]
stationInfo$long <- dat$Lon[unik]
head(stationInfo)
which(!complete.cases(stationInfo))
B2 <- data.frame(No=B$No, NN.sigma)
dim(stationInfo)
Plot_nonInt(B2$lat, B2$long,
B2$NN.sigma, world, "sigma dis.")
class(B2$lat)
class(B2$long)
class(B2$NN.sigma)
class(world)
Plot_nonInt(B2$lat, B2$long,
B2$NN.sigma, world, "sigma dis.")
rm(list=ls())
source("src/Novelty_Oceans_Functions.R")
source("src/Novelty_Oceans_Functions.R")
clean_pkgs()
source("src/Novelty_Oceans_Functions.R")
#dat <- fread("data/large_files/Data_OceNov.txt", sep = ",")
dat <- fread("data/large_files/ESM2M_2000_RCP8.5.txt", sep = ",")
dat_1800 <- dat %>% filter(Year<1850)
dim(dat_1800)
dat_2000 <-   dat %>% filter(Year>1960 & Year<2010)
dim(dat_2000)
dat_2100 <-   dat %>% filter(Year>2050)
dim(dat_2100)
norm_1800 <- calculate_normals(dat_1800)
norm_2000 <- calculate_normals(dat_2000)
norm_2100 <- calculate_normals(dat_2100)
#--------------------------------
### data frame to link station number to Lat Long ####
#--------------------------------
head(dat)
min(which(dat$No==2))
stations <- unique(dat$No)
stationInfo = data.frame(stations=stations, lat=NA, long=NA)
unik <- which(!duplicated(dat$No))
head(unik)
stationInfo$lat <- dat$Lat[unik]
stationInfo$long <- dat$Lon[unik]
head(stationInfo)
which(!complete.cases(stationInfo))
A <- norm_1800
# 1800-1830 climate normals
head(A)
dim(A)
B <- norm_2000[norm_2000$No %in% norm_1800$No,]
# 1970-2000 climate normals
head(B)
dim(B)
# sanity check to make sure stations in right order
identical(A$No, B$No) # should be true
head(dat_2000)
C <- data.frame(dat_2000[,c(1,6,7,8)], dat_2000[,c(6,7,8)])
head(C)
C.id <- C$No
proxy <- B$No
# Principal component truncation rule
trunc.SDs <- 0.1 #truncation
#initiate the data frame to store the projected sigma dissimilarity of best analogs for each grid cell.
NN.sigma <- rep(NA,length(proxy))
for(j in sort(unique(proxy))){
# run the novelty calculation once for each ICV proxy.
# Takes about 1.5 sec/iteration on a typical laptop.
## Select data relevant to ICV proxy j
Bj <- B[which(proxy==j),]   # future climates
# select locations for which ICV proxy j is the closest ICV proxy.
Cj <- C[which(C.id==j),]    # reference period ICV at ICV proxy j
## Step 1: express climate data as standardized anomalies of reference period
#  ICV at ICV proxy j.
Cj.sd <- apply(Cj,2,sd, na.rm=T)  #standard deviation of interannual variability in each climate variable, ignoring missing years
#standard deviation of variability in each climate
# variable, ignoring missing years
A.prime <- sweep(A[,2:7],MARGIN=2,Cj.sd[2:7],`/`) #standardize the reference ICV
# a <- matrix(c(1,2,3,4,5,6), nrow=2)
# sweep(a, MARGIN =2, STATS=c(2,3,4)) # subtracts STATs from each column
# sweep(a, MARGIN =2, STATS=c(2,3,4), FUN=`/`) # divides each column by STATS
Bj.prime <- sweep(Bj[,2:7],MARGIN=2,Cj.sd[2:7],`/`) #standardize the analog pool
Cj.prime <- sweep(Cj[,2:7],MARGIN=2,Cj.sd[2:7],`/`) #standardize the projected future conditions of grid cells represented by ICV proxy j
colnames(Cj.prime) <- colnames(A.prime)
## Step 2: Extract the principal components (PCs) of the reference period ICV
# and project all data onto these PCs
PCA <- prcomp(Cj.prime[!is.na(apply(Cj.prime,1,mean)),])
# Principal components analysis. The !is.na(apply(...)) term is there
# simply to select all years with complete observations in all variables.
PCA$rotation
#plot(PCA$rotation[,1], PCA$rotation[,2], xlim=c(-0.43, -0.39))
#text(PCA$rotation[,1], PCA$rotation[,2], rownames(PCA$rotation))
# SST summer and winter in lower right of PC space,
# Arag and Calc in upper left of PC space
#plot(PCA$rotation[,1], PCA$rotation[,3], xlim=c(-0.43, -0.39))
#text(PCA$rotation[,1], PCA$rotation[,3], rownames(PCA$rotation))
# separates the three variables
#plot(PCA$sdev)
#round(PCA$sdev, 2)
PCs <- max(which(unlist(summary(PCA)[1])>trunc.SDs))
# find the number of PCs to retain using the PC truncation
# rule of eigenvector stdev > the truncation threshold
X <- as.data.frame(predict(PCA,A.prime))
# project the analog pool onto the PCs
head(X)
Yj <- as.data.frame(predict(PCA,Bj.prime))
# project the projected future conditions onto the PCs
Zj <- as.data.frame(predict(PCA,Cj.prime))
# project the reference ICV onto the PCs
#plot(X[,1], X[,2]) # analog
#points(Zj[,1], Zj[,2], pch=19, col=rgb(1,0,0, 0.5)) # reference ICV
#points(Yj[,1], Yj[,2], pch=19, col=rgb(0,1,0)) # future conditions
## Step 3a: express PC scores as standardized anomalies of reference interannual variability
Zj.sd <- apply(Zj,2,sd, na.rm=T)
#standard deviation of 1951-1990 interannual variability in each principal component, ignoring missing years
#Zj.sd
X.prime <- sweep(X,MARGIN=2,Zj.sd,`/`)
#standardize the analog pool
#head(X.prime)
Yj.prime <- sweep(Yj,MARGIN=2,Zj.sd,`/`)
#standardize the projected conditions
#Yj.prime
## Step 3b: find the sigma dissimilarity of each projected condition with
# its best analog (Euclidean nearest neighbour) in the observed analog pool.
X.prime <- X.prime[complete.cases(X.prime),]
NN.dist <- as.vector(get.knnx(data=X.prime[,1:PCs],
query=Yj.prime[,1:PCs],
k=1,algorithm="brute")[[2]])
# Euclidean nearest neighbour distance in the z-standardized PCs of
# interannual climatic variability, i.e. the Mahalanobian nearest neighbour.
NN.chi <- pchi(NN.dist,PCs) # percentile of the nearest neighbour
# distance on the chi distribution with degrees of freedom
# equaling the dimensionality of the distance measurement (PCs)
NN.sigma[which(proxy==j)] <- qchi(NN.chi,1)
# values of the chi percentiles on a standard half-normal distribution (chi distribution with one degree of freedom)
if(j%%10==0){print(j)}
}
dim(A)
dim(B)
head(NN.sigma)
NN.sigma[which(is.infinite(NN.sigma))] <- NA
#which(is.na(NN.sigma))
tail(sort(NN.sigma))
length(NN.sigma)
B2 <- data.frame(No=B$No, NN.sigma)
B2 <- merge(B2, stationInfo, by.x="No", by.y="stations", all.x=TRUE)
# Visualize
world <- map_data("world2")
dim(stationInfo)
Plot_nonInt(B2$lat, B2$long,
B2$NN.sigma, world, "sigma dis.")
warnings()
class(B)
dim(A)
dim(B)
head(NN.sigma)
B2 <- data.frame(No=B$No, NN.sigma)
B2 <- merge(B2, stationInfo, by.x="No", by.y="stations", all.x=TRUE)
plot(B2$NN.sigma)
warnings()
#write.csv(NN.sigma,"NN.sigma.RCP45.GlobalMean.2085.csv", row.names=FALSE)
#write.csv(B2,"Sigma.RCP85.today_1800.csv", row.names=FALSE)
B3<-fread("./data/Sigma.RCP85.today_1800.csv")
head(B2)
head(B3)
str(B2)
str(B3)
